# -*- coding: utf-8 -*-
"""Classificacao.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-o6A3xt6LWAotG3hDAVf0YKPak3TzviX

# Classificação com dados desbalanceados
## População e Amostra
Algoritimo Naive Bayes

## Carregamento da base de dados
"""

import pandas as pd 
import numpy as np
import seaborn as sns
import random
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from imblearn.under_sampling import TomekLinks
from imblearn.over_sampling import SMOTE

dataset = pd.read_csv('credit_data.csv')

dataset.shape

dataset.head()

dataset.tail()

dataset.dropna(inplace=True)
dataset.shape

sns.countplot(dataset['c#default']);

X = dataset.iloc[:, 1:4].values

X.shape

X

y = dataset.iloc[:, 4].values

y.shape

y

"""## Base de treinamento e teste"""

X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(X, y, test_size=0.2, stratify=y)

X_treinamento.shape, y_treinamento.shape

X_teste.shape, y_teste.shape

np.unique(y, return_counts=True)

1714 / len(dataset), 283 / len(dataset)

np.unique(y_treinamento, return_counts=True)

226 / len(y_treinamento)

np.unique(y_teste, return_counts=True)

57 / len(y_teste)

"""## Classificação com Naive Bayes"""

modelo = GaussianNB()
modelo.fit(X_treinamento, y_treinamento)

previsoes = modelo.predict(X_teste)

previsoes

y_teste

accuracy_score(previsoes, y_teste)

cm = confusion_matrix(previsoes, y_teste)
cm

sns.heatmap(cm, annot=True)

(340 + 32) / (340 + 25 + 32 + 3)

# Percentual de acerto para pessoas que pagam o empréstimo
340 / (340 + 25)

# Percentual de acerto para pessoas que não pagam o empréstimo
32 / (32 + 7)

# Perdas: 5.000
# Clientes não pagadores: 1.000
1000 * 18 / 100

180 * 5000

"""## Subamostragem (undersampling) - Tomek Links"""

tl = TomekLinks(sampling_strategy='majority')
X_under, y_under = tl.fit_resample(X, y)

X_under.shape, y_under.shape

np.unique(y, return_counts=True)

np.unique(y_under, return_counts=True)

X_treinamento_u, X_teste_u, y_treinamento_u, y_teste_u = train_test_split(X_under,
                                                                          y_under,
                                                                          test_size=0.2,
                                                                          stratify=y_under)
X_treinamento_u.shape, X_teste_u.shape

modelo_u = GaussianNB()
modelo_u.fit(X_treinamento_u, y_treinamento_u)
previsoes_u = modelo_u.predict(X_teste_u)
accuracy_score(y_teste_u,previsoes_u)

cm_u = confusion_matrix(previsoes_u, y_teste_u) 
cm_u

311 / (311 + 29)

31 / (31 + 12)

"""## Sobreamostragem (oversampling) - SMOTE"""

smote = SMOTE(sampling_strategy='minority')
X_over, y_over = smote.fit_resample(X, y)

X_over.shape, y_over.shape

np.unique(y, return_counts=True)

np.unique(y_over, return_counts=True)

X_treinamento_o, X_teste_o, y_treinamento_o, y_teste_o = train_test_split(X_over, y_over,
                                                                          test_size = 0.2,
                                                                          stratify = y_over)

X_treinamento_o.shape, X_teste_o.shape

modelo_o = GaussianNB()
modelo_o.fit(X_treinamento_o, y_treinamento_o)
previsoes_o = modelo_o.predict(X_teste_o)
accuracy_score(previsoes_o, y_teste_o)

cm_o = confusion_matrix(previsoes_o, y_teste_o)
cm_o

295 / (295 + 12)

331 / (331 + 48)

